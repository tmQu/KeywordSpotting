{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model.DS_CNN import DS_CNN\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data from X_train.npy and y_train.npy\n",
    "X_train = np.load('X_train.npy')\n",
    "y_train = np.load('y_train.npy')\n",
    "\n",
    "#load data from X_test.npy and y_test.npy\n",
    "X_test = np.load('X_test.npy')\n",
    "y_test = np.load('y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3686, 650)\n",
      "(3686,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DS_CNN((650, 1), 3).build_model()\n",
    "\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "# model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "# model.fit(X_train, y_train, epochs=1, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to file\n",
    "# model.save_weights('model_weight')  # save the weights of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nq201\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# convert to stream model\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "import zipfile\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf1\n",
    "import logging\n",
    "from kws_streaming.models import model_params\n",
    "from kws_streaming.models import model_flags\n",
    "from kws_streaming.train import test\n",
    "from kws_streaming.models import utils\n",
    "from kws_streaming.models import models\n",
    "from kws_streaming import data\n",
    "tf1.disable_eager_execution()\n",
    "\n",
    "\n",
    "config = tf1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf1.Session(config=config)\n",
    "\n",
    "\n",
    "# general imports\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import scipy as scipy\n",
    "import scipy.io.wavfile as wav\n",
    "import scipy.signal\n",
    "\n",
    "tf1.reset_default_graph()\n",
    "sess = tf1.Session()\n",
    "tf1.keras.backend.set_session(sess)\n",
    "tf1.keras.backend.set_learning_phase(0)\n",
    "\n",
    "\n",
    "def my_to_streaming_inference(model_non_stream, default_size ,mode):\n",
    "  tf.keras.backend.set_learning_phase(0)\n",
    "  input_data_shape = (default_size // 5,)\n",
    "  input_tensors = [\n",
    "      tf.keras.layers.Input(\n",
    "          shape=130, batch_size=1, name='input_audio')\n",
    "    ]\n",
    "  model_inference = utils.convert_to_inference_model(model_non_stream, input_tensors,\n",
    "                                               mode)\n",
    "  return model_inference\n",
    "\n",
    "\n",
    "# model_non_stream_batch = model\n",
    "\n",
    "# #\n",
    "# tf.keras.backend.set_learning_phase(0)\n",
    "# model_stream = my_to_streaming_inference(model_non_stream_batch, 650, Modes.STREAM_INTERNAL_STATE_INFERENCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 650)]             0         \n",
      "                                                                 \n",
      " my_reshape (MyReshape)      (None, 10, 65, 1)         0         \n",
      "                                                                 \n",
      " stream (Stream)             (None, 7, 62, 16)         256       \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 7, 62, 16)        64        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " activation (Activation)     (None, 7, 62, 16)         0         \n",
      "                                                                 \n",
      " stream_1 (Stream)           (None, 6, 61, 16)         64        \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 6, 61, 16)        64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 6, 61, 16)         0         \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 6, 61, 16)         256       \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 6, 61, 16)        64        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 6, 61, 16)         0         \n",
      "                                                                 \n",
      " stream_2 (Stream)           (None, 1, 1, 16)          0         \n",
      "                                                                 \n",
      " stream_3 (Stream)           (None, 16)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 51        \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 3)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 819\n",
      "Trainable params: 723\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# visualize a model\n",
    "from model.DS_CNN import DS_CNN\n",
    "# import kws_streaming.layers.stream as stream\n",
    "\n",
    "SMALL_INPUT = 65\n",
    "\n",
    "model_non_stream_batch = DS_CNN((650), 3 ,model_size_info = [2, 16, 4, 4, 1, 1, 16, 2, 2, 1, 1], reshape=SMALL_INPUT).build_model()\n",
    "# model_non_stream_batch = DS_CNN((650), 3,  model_size_info = [3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 32, 1, 1, 1, 1]).build_model()\n",
    "# \n",
    "# model_non_stream_batch = models.MODELS[MODEL_NAME](flags)\n",
    "\n",
    "model_non_stream_batch.summary()\n",
    "\n",
    "# save the model to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3317 samples, validate on 369 samples\n",
      "Epoch 1/100\n",
      "3317/3317 [==============================] - 1s 314us/sample - loss: 0.7817 - accuracy: 0.6427 - val_loss: 0.8007 - val_accuracy: 0.6260\n",
      "Epoch 2/100\n",
      " 224/3317 [=>............................] - ETA: 0s - loss: 0.4863 - accuracy: 0.8304"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nq201\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2335: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates = self.state_updates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3317/3317 [==============================] - 1s 272us/sample - loss: 0.4262 - accuracy: 0.8475 - val_loss: 0.4433 - val_accuracy: 0.8374\n",
      "Epoch 3/100\n",
      "3317/3317 [==============================] - 1s 257us/sample - loss: 0.3443 - accuracy: 0.8719 - val_loss: 0.3927 - val_accuracy: 0.8726\n",
      "Epoch 4/100\n",
      "3317/3317 [==============================] - 1s 283us/sample - loss: 0.3320 - accuracy: 0.8830 - val_loss: 0.5002 - val_accuracy: 0.8130\n",
      "Epoch 5/100\n",
      "3317/3317 [==============================] - 1s 262us/sample - loss: 0.2890 - accuracy: 0.8966 - val_loss: 0.4556 - val_accuracy: 0.8564\n",
      "Epoch 6/100\n",
      "3317/3317 [==============================] - 1s 259us/sample - loss: 0.3247 - accuracy: 0.8848 - val_loss: 0.4692 - val_accuracy: 0.8266\n",
      "Epoch 7/100\n",
      "3317/3317 [==============================] - 1s 302us/sample - loss: 0.2839 - accuracy: 0.8957 - val_loss: 0.3877 - val_accuracy: 0.8672\n",
      "Epoch 8/100\n",
      "3317/3317 [==============================] - 1s 280us/sample - loss: 0.2530 - accuracy: 0.9068 - val_loss: 0.3670 - val_accuracy: 0.8835\n",
      "Epoch 9/100\n",
      "3317/3317 [==============================] - 1s 305us/sample - loss: 0.2361 - accuracy: 0.9111 - val_loss: 0.4245 - val_accuracy: 0.8591\n",
      "Epoch 10/100\n",
      "3317/3317 [==============================] - 1s 307us/sample - loss: 0.2516 - accuracy: 0.9120 - val_loss: 0.3906 - val_accuracy: 0.8591\n",
      "Epoch 11/100\n",
      "3317/3317 [==============================] - 1s 263us/sample - loss: 0.2244 - accuracy: 0.9156 - val_loss: 0.3202 - val_accuracy: 0.8889\n",
      "Epoch 12/100\n",
      "3317/3317 [==============================] - 1s 266us/sample - loss: 0.2312 - accuracy: 0.9132 - val_loss: 0.3396 - val_accuracy: 0.8835\n",
      "Epoch 13/100\n",
      "3317/3317 [==============================] - 1s 317us/sample - loss: 0.2542 - accuracy: 0.9038 - val_loss: 0.5839 - val_accuracy: 0.7805\n",
      "Epoch 14/100\n",
      "3317/3317 [==============================] - 1s 311us/sample - loss: 0.2331 - accuracy: 0.9123 - val_loss: 0.3419 - val_accuracy: 0.8835\n",
      "Epoch 15/100\n",
      "3317/3317 [==============================] - 1s 258us/sample - loss: 0.2093 - accuracy: 0.9228 - val_loss: 0.3382 - val_accuracy: 0.8835\n",
      "Epoch 16/100\n",
      "3317/3317 [==============================] - 1s 296us/sample - loss: 0.1966 - accuracy: 0.9249 - val_loss: 0.3078 - val_accuracy: 0.8997\n",
      "Epoch 17/100\n",
      "3317/3317 [==============================] - 1s 286us/sample - loss: 0.2077 - accuracy: 0.9204 - val_loss: 0.3211 - val_accuracy: 0.8916\n",
      "Epoch 18/100\n",
      "3317/3317 [==============================] - 1s 261us/sample - loss: 0.1973 - accuracy: 0.9255 - val_loss: 0.3463 - val_accuracy: 0.8970\n",
      "Epoch 19/100\n",
      "3317/3317 [==============================] - 1s 265us/sample - loss: 0.2206 - accuracy: 0.9189 - val_loss: 0.3420 - val_accuracy: 0.8943\n",
      "Epoch 20/100\n",
      "3317/3317 [==============================] - 1s 257us/sample - loss: 0.1962 - accuracy: 0.9258 - val_loss: 0.3335 - val_accuracy: 0.8997\n",
      "Epoch 21/100\n",
      "3317/3317 [==============================] - 1s 246us/sample - loss: 0.1968 - accuracy: 0.9289 - val_loss: 0.3172 - val_accuracy: 0.8970\n",
      "Epoch 22/100\n",
      "3317/3317 [==============================] - 1s 268us/sample - loss: 0.1960 - accuracy: 0.9264 - val_loss: 0.2973 - val_accuracy: 0.9079\n",
      "Epoch 23/100\n",
      "3317/3317 [==============================] - 1s 265us/sample - loss: 0.1784 - accuracy: 0.9346 - val_loss: 0.3168 - val_accuracy: 0.8943\n",
      "Epoch 24/100\n",
      "3317/3317 [==============================] - 1s 249us/sample - loss: 0.2037 - accuracy: 0.9207 - val_loss: 0.3368 - val_accuracy: 0.8943\n",
      "Epoch 25/100\n",
      "3317/3317 [==============================] - 1s 231us/sample - loss: 0.1838 - accuracy: 0.9310 - val_loss: 0.2954 - val_accuracy: 0.9106\n",
      "Epoch 26/100\n",
      "3317/3317 [==============================] - 1s 250us/sample - loss: 0.1708 - accuracy: 0.9346 - val_loss: 0.2974 - val_accuracy: 0.8997\n",
      "Epoch 27/100\n",
      "3317/3317 [==============================] - 1s 274us/sample - loss: 0.1690 - accuracy: 0.9364 - val_loss: 0.3134 - val_accuracy: 0.9106\n",
      "Epoch 28/100\n",
      "3317/3317 [==============================] - 1s 329us/sample - loss: 0.1839 - accuracy: 0.9307 - val_loss: 0.3384 - val_accuracy: 0.8889\n",
      "Epoch 29/100\n",
      "3317/3317 [==============================] - 1s 258us/sample - loss: 0.1983 - accuracy: 0.9246 - val_loss: 0.3237 - val_accuracy: 0.9051\n",
      "Epoch 30/100\n",
      "3317/3317 [==============================] - 1s 250us/sample - loss: 0.1606 - accuracy: 0.9361 - val_loss: 0.3289 - val_accuracy: 0.9024\n",
      "Epoch 31/100\n",
      "3317/3317 [==============================] - 1s 279us/sample - loss: 0.1707 - accuracy: 0.9370 - val_loss: 0.4625 - val_accuracy: 0.8753\n",
      "Epoch 32/100\n",
      "3317/3317 [==============================] - 1s 245us/sample - loss: 0.1865 - accuracy: 0.9304 - val_loss: 0.4035 - val_accuracy: 0.8726\n",
      "Epoch 33/100\n",
      "3317/3317 [==============================] - 1s 257us/sample - loss: 0.1846 - accuracy: 0.9270 - val_loss: 0.3993 - val_accuracy: 0.8753\n",
      "Epoch 34/100\n",
      "3317/3317 [==============================] - 1s 261us/sample - loss: 0.1586 - accuracy: 0.9394 - val_loss: 0.3047 - val_accuracy: 0.9079\n",
      "Epoch 35/100\n",
      "3317/3317 [==============================] - 1s 303us/sample - loss: 0.1658 - accuracy: 0.9358 - val_loss: 0.3184 - val_accuracy: 0.8970\n",
      "Epoch 36/100\n",
      "3317/3317 [==============================] - 1s 259us/sample - loss: 0.1633 - accuracy: 0.9364 - val_loss: 0.4439 - val_accuracy: 0.8537\n",
      "Epoch 37/100\n",
      "3317/3317 [==============================] - 1s 273us/sample - loss: 0.1811 - accuracy: 0.9379 - val_loss: 0.3041 - val_accuracy: 0.9051\n",
      "Epoch 38/100\n",
      "3317/3317 [==============================] - 1s 277us/sample - loss: 0.1713 - accuracy: 0.9382 - val_loss: 0.3582 - val_accuracy: 0.8943\n",
      "Epoch 39/100\n",
      "3317/3317 [==============================] - 1s 303us/sample - loss: 0.1598 - accuracy: 0.9394 - val_loss: 0.3200 - val_accuracy: 0.8943\n",
      "Epoch 40/100\n",
      "3317/3317 [==============================] - 1s 260us/sample - loss: 0.1602 - accuracy: 0.9412 - val_loss: 0.3312 - val_accuracy: 0.8997\n",
      "Epoch 41/100\n",
      "3317/3317 [==============================] - 1s 264us/sample - loss: 0.1753 - accuracy: 0.9349 - val_loss: 0.3058 - val_accuracy: 0.8997\n",
      "Epoch 42/100\n",
      "3317/3317 [==============================] - 1s 264us/sample - loss: 0.1407 - accuracy: 0.9475 - val_loss: 0.3055 - val_accuracy: 0.8997\n",
      "Epoch 43/100\n",
      "3317/3317 [==============================] - 1s 269us/sample - loss: 0.1406 - accuracy: 0.9472 - val_loss: 0.3240 - val_accuracy: 0.8943\n",
      "Epoch 44/100\n",
      "3317/3317 [==============================] - 1s 217us/sample - loss: 0.1819 - accuracy: 0.9289 - val_loss: 0.3404 - val_accuracy: 0.9051\n",
      "Epoch 45/100\n",
      "3317/3317 [==============================] - 1s 244us/sample - loss: 0.1743 - accuracy: 0.9349 - val_loss: 0.3361 - val_accuracy: 0.8970\n",
      "Epoch 46/100\n",
      "3317/3317 [==============================] - 1s 278us/sample - loss: 0.1381 - accuracy: 0.9484 - val_loss: 0.3377 - val_accuracy: 0.8916\n",
      "Epoch 47/100\n",
      "3317/3317 [==============================] - 1s 285us/sample - loss: 0.1476 - accuracy: 0.9436 - val_loss: 0.3375 - val_accuracy: 0.8889\n",
      "Epoch 48/100\n",
      "3317/3317 [==============================] - 1s 270us/sample - loss: 0.1388 - accuracy: 0.9460 - val_loss: 0.3418 - val_accuracy: 0.8970\n",
      "Epoch 49/100\n",
      "3317/3317 [==============================] - 1s 311us/sample - loss: 0.1454 - accuracy: 0.9460 - val_loss: 0.3298 - val_accuracy: 0.8997\n",
      "Epoch 50/100\n",
      "3317/3317 [==============================] - 1s 309us/sample - loss: 0.1597 - accuracy: 0.9382 - val_loss: 0.3325 - val_accuracy: 0.8970\n",
      "Epoch 51/100\n",
      "3317/3317 [==============================] - 1s 282us/sample - loss: 0.1472 - accuracy: 0.9469 - val_loss: 0.3322 - val_accuracy: 0.8808\n",
      "Epoch 52/100\n",
      "3317/3317 [==============================] - 1s 285us/sample - loss: 0.1655 - accuracy: 0.9397 - val_loss: 0.3334 - val_accuracy: 0.8970\n",
      "Epoch 53/100\n",
      "3317/3317 [==============================] - 1s 310us/sample - loss: 0.1460 - accuracy: 0.9439 - val_loss: 0.3173 - val_accuracy: 0.9024\n",
      "Epoch 54/100\n",
      "3317/3317 [==============================] - 1s 282us/sample - loss: 0.1280 - accuracy: 0.9518 - val_loss: 0.4094 - val_accuracy: 0.8835\n",
      "Epoch 55/100\n",
      "3317/3317 [==============================] - 1s 314us/sample - loss: 0.1341 - accuracy: 0.9500 - val_loss: 0.3720 - val_accuracy: 0.8862\n",
      "Epoch 56/100\n",
      "3317/3317 [==============================] - 1s 290us/sample - loss: 0.1308 - accuracy: 0.9503 - val_loss: 0.3841 - val_accuracy: 0.8997\n",
      "Epoch 57/100\n",
      "3317/3317 [==============================] - 1s 276us/sample - loss: 0.1331 - accuracy: 0.9484 - val_loss: 0.3674 - val_accuracy: 0.8835\n",
      "Epoch 58/100\n",
      "3317/3317 [==============================] - 1s 293us/sample - loss: 0.1509 - accuracy: 0.9403 - val_loss: 0.3475 - val_accuracy: 0.8997\n",
      "Epoch 59/100\n",
      "3317/3317 [==============================] - 1s 272us/sample - loss: 0.1692 - accuracy: 0.9352 - val_loss: 0.3352 - val_accuracy: 0.8889\n",
      "Epoch 60/100\n",
      "3317/3317 [==============================] - 1s 274us/sample - loss: 0.1316 - accuracy: 0.9518 - val_loss: 0.3696 - val_accuracy: 0.8862\n",
      "Epoch 61/100\n",
      "3317/3317 [==============================] - 1s 285us/sample - loss: 0.1366 - accuracy: 0.9475 - val_loss: 0.3199 - val_accuracy: 0.8943\n",
      "Epoch 62/100\n",
      "3317/3317 [==============================] - 1s 296us/sample - loss: 0.1346 - accuracy: 0.9497 - val_loss: 0.4728 - val_accuracy: 0.8835\n",
      "Epoch 63/100\n",
      "3317/3317 [==============================] - 1s 283us/sample - loss: 0.1482 - accuracy: 0.9445 - val_loss: 0.4337 - val_accuracy: 0.8862\n",
      "Epoch 64/100\n",
      "3317/3317 [==============================] - 1s 295us/sample - loss: 0.1999 - accuracy: 0.9234 - val_loss: 0.3395 - val_accuracy: 0.8808\n",
      "Epoch 65/100\n",
      "3317/3317 [==============================] - 1s 286us/sample - loss: 0.1269 - accuracy: 0.9500 - val_loss: 0.4010 - val_accuracy: 0.8835\n",
      "Epoch 66/100\n",
      "3317/3317 [==============================] - 1s 280us/sample - loss: 0.1253 - accuracy: 0.9533 - val_loss: 0.3763 - val_accuracy: 0.8808\n",
      "Epoch 67/100\n",
      "3317/3317 [==============================] - 1s 301us/sample - loss: 0.1278 - accuracy: 0.9497 - val_loss: 0.3864 - val_accuracy: 0.9024\n",
      "Epoch 68/100\n",
      "3317/3317 [==============================] - 1s 281us/sample - loss: 0.1301 - accuracy: 0.9518 - val_loss: 0.3637 - val_accuracy: 0.8943\n",
      "Epoch 69/100\n",
      "3317/3317 [==============================] - 1s 285us/sample - loss: 0.1438 - accuracy: 0.9475 - val_loss: 0.4030 - val_accuracy: 0.8862\n",
      "Epoch 70/100\n",
      "3317/3317 [==============================] - 1s 283us/sample - loss: 0.1353 - accuracy: 0.9475 - val_loss: 0.4725 - val_accuracy: 0.8780\n",
      "Epoch 71/100\n",
      "3317/3317 [==============================] - 1s 279us/sample - loss: 0.1391 - accuracy: 0.9500 - val_loss: 0.3555 - val_accuracy: 0.8997\n",
      "Epoch 72/100\n",
      "3317/3317 [==============================] - 1s 286us/sample - loss: 0.1182 - accuracy: 0.9569 - val_loss: 0.4129 - val_accuracy: 0.8780\n",
      "Epoch 73/100\n",
      "3317/3317 [==============================] - 1s 260us/sample - loss: 0.1257 - accuracy: 0.9563 - val_loss: 0.4213 - val_accuracy: 0.8916\n",
      "Epoch 74/100\n",
      "3317/3317 [==============================] - 1s 258us/sample - loss: 0.1203 - accuracy: 0.9554 - val_loss: 0.3522 - val_accuracy: 0.8808\n",
      "Epoch 75/100\n",
      "3317/3317 [==============================] - 1s 251us/sample - loss: 0.1491 - accuracy: 0.9445 - val_loss: 0.4284 - val_accuracy: 0.8889\n",
      "Epoch 76/100\n",
      "3317/3317 [==============================] - 1s 264us/sample - loss: 0.1313 - accuracy: 0.9491 - val_loss: 0.3345 - val_accuracy: 0.8997\n",
      "Epoch 77/100\n",
      "3317/3317 [==============================] - 1s 245us/sample - loss: 0.1163 - accuracy: 0.9569 - val_loss: 0.4696 - val_accuracy: 0.8537\n",
      "Epoch 78/100\n",
      "3317/3317 [==============================] - 1s 261us/sample - loss: 0.1486 - accuracy: 0.9409 - val_loss: 0.3535 - val_accuracy: 0.8889\n",
      "Epoch 79/100\n",
      "3317/3317 [==============================] - 1s 230us/sample - loss: 0.1103 - accuracy: 0.9620 - val_loss: 0.3768 - val_accuracy: 0.8943\n",
      "Epoch 80/100\n",
      "3317/3317 [==============================] - 1s 244us/sample - loss: 0.0988 - accuracy: 0.9665 - val_loss: 0.3809 - val_accuracy: 0.8916\n",
      "Epoch 81/100\n",
      "3317/3317 [==============================] - 1s 291us/sample - loss: 0.1104 - accuracy: 0.9614 - val_loss: 0.4257 - val_accuracy: 0.8943\n",
      "Epoch 82/100\n",
      "3317/3317 [==============================] - 1s 307us/sample - loss: 0.1353 - accuracy: 0.9484 - val_loss: 0.4710 - val_accuracy: 0.8753\n",
      "Epoch 83/100\n",
      "3317/3317 [==============================] - 1s 338us/sample - loss: 0.1729 - accuracy: 0.9391 - val_loss: 0.3667 - val_accuracy: 0.8889\n",
      "Epoch 84/100\n",
      "3317/3317 [==============================] - 1s 281us/sample - loss: 0.0989 - accuracy: 0.9638 - val_loss: 0.4378 - val_accuracy: 0.8889\n",
      "Epoch 85/100\n",
      "3317/3317 [==============================] - 1s 270us/sample - loss: 0.1423 - accuracy: 0.9472 - val_loss: 0.4058 - val_accuracy: 0.8780\n",
      "Epoch 86/100\n",
      "3317/3317 [==============================] - 1s 260us/sample - loss: 0.1119 - accuracy: 0.9602 - val_loss: 0.3894 - val_accuracy: 0.8808\n",
      "Epoch 87/100\n",
      "3317/3317 [==============================] - 1s 276us/sample - loss: 0.1047 - accuracy: 0.9641 - val_loss: 0.4047 - val_accuracy: 0.8916\n",
      "Epoch 88/100\n",
      "3317/3317 [==============================] - 1s 297us/sample - loss: 0.0938 - accuracy: 0.9665 - val_loss: 0.3868 - val_accuracy: 0.8889\n",
      "Epoch 89/100\n",
      "3317/3317 [==============================] - 1s 292us/sample - loss: 0.1322 - accuracy: 0.9515 - val_loss: 0.4191 - val_accuracy: 0.8835\n",
      "Epoch 90/100\n",
      "3317/3317 [==============================] - 1s 232us/sample - loss: 0.1348 - accuracy: 0.9527 - val_loss: 0.4623 - val_accuracy: 0.8780\n",
      "Epoch 91/100\n",
      "3317/3317 [==============================] - 1s 245us/sample - loss: 0.1123 - accuracy: 0.9584 - val_loss: 0.3701 - val_accuracy: 0.8916\n",
      "Epoch 92/100\n",
      "3317/3317 [==============================] - 1s 262us/sample - loss: 0.1083 - accuracy: 0.9617 - val_loss: 0.5315 - val_accuracy: 0.8591\n",
      "Epoch 93/100\n",
      "3317/3317 [==============================] - 1s 270us/sample - loss: 0.1163 - accuracy: 0.9554 - val_loss: 0.4136 - val_accuracy: 0.8672\n",
      "Epoch 94/100\n",
      "3317/3317 [==============================] - 1s 267us/sample - loss: 0.1217 - accuracy: 0.9557 - val_loss: 0.3921 - val_accuracy: 0.8862\n",
      "Epoch 95/100\n",
      "3317/3317 [==============================] - 1s 272us/sample - loss: 0.1199 - accuracy: 0.9569 - val_loss: 0.4607 - val_accuracy: 0.8699\n",
      "Epoch 96/100\n",
      "3317/3317 [==============================] - 1s 264us/sample - loss: 0.1062 - accuracy: 0.9575 - val_loss: 0.4180 - val_accuracy: 0.8862\n",
      "Epoch 97/100\n",
      "3317/3317 [==============================] - 1s 265us/sample - loss: 0.0922 - accuracy: 0.9659 - val_loss: 0.4007 - val_accuracy: 0.8835\n",
      "Epoch 98/100\n",
      "3317/3317 [==============================] - 1s 290us/sample - loss: 0.1345 - accuracy: 0.9560 - val_loss: 0.3912 - val_accuracy: 0.8862\n",
      "Epoch 99/100\n",
      "3317/3317 [==============================] - 1s 271us/sample - loss: 0.1240 - accuracy: 0.9509 - val_loss: 0.3995 - val_accuracy: 0.8916\n",
      "Epoch 100/100\n",
      "3317/3317 [==============================] - 1s 245us/sample - loss: 0.0976 - accuracy: 0.9668 - val_loss: 0.4223 - val_accuracy: 0.8699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8ffa54cd0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from kws_streaming.train.my_train import train\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "\n",
    "# model_non_stream_batch = train(flags, X_train, y_train, X_test, y_test, model_non_stream_batch)\n",
    "learning_rate = 0.01\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model_non_stream_batch.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model_non_stream_batch.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_to_streaming_inference(model_non_stream, size ,mode):\n",
    "  tf.keras.backend.set_learning_phase(0)\n",
    "  input_tensors = [\n",
    "      tf.keras.layers.Input(\n",
    "          shape=(size), batch_size=1,name='input_audio')\n",
    "    ]\n",
    "  model_inference = utils.convert_to_inference_model(model_non_stream, input_tensors,\n",
    "                                               mode)\n",
    "  return model_inference\n",
    "\n",
    "# from kws_streaming.layers.modes import Modes\n",
    "\n",
    "# model_stream = my_to_streaming_inference(model_non_stream_batch, flags, Modes.STREAM_INTERNAL_STATE_INFERENCE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTERNAL MODEL\n",
    "\n",
    "# from kws_streaming.layers.modes import Modes\n",
    "\n",
    "# model_stream = my_to_streaming_inference(model_non_stream_batch, flags, Modes.STREAM_INTERNAL_STATE_INFERENCE)\n",
    "\n",
    "\n",
    "# tf.saved_model.save(model_stream, 'model_stream_in')\n",
    "# tf_lite = saved_model_to_tflite('model_stream_in')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 4\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 2\n",
      "WARNING:absl:ring_buffer_size_in_time_dim overwritten by the passed-in value: 6\n",
      "WARNING:absl:There is no need to use Stream on time dim with size 1: flatten\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_audio (InputLayer)       [(1, 65)]            0           []                               \n",
      "                                                                                                  \n",
      " my_reshape (MyReshape)         (1, 1, 65, 1)        0           ['input_audio[0][0]']            \n",
      "                                                                                                  \n",
      " stream (Stream)                (1, 1, 62, 16)       256         ['my_reshape[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (1, 1, 62, 16)      64          ['stream[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (1, 1, 62, 16)       0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " stream_1 (Stream)              (1, 1, 61, 16)       64          ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (1, 1, 61, 16)      64          ['stream_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (1, 1, 61, 16)       0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (1, 1, 61, 16)       256         ['activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (1, 1, 61, 16)      64          ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (1, 1, 61, 16)       0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " stream_2 (Stream)              (1, 1, 1, 16)        0           ['activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " stream_3 (Stream)              (1, 16)              0           ['stream_2[0][0]']               \n",
      "                                                                                                  \n",
      " stream/ExternalState (InputLay  [(1, 4, 65, 1)]     0           []                               \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " stream_1/ExternalState (InputL  [(1, 2, 62, 16)]    0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " stream_2/ExternalState (InputL  [(1, 6, 61, 16)]    0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " stream_3/ExternalState (InputL  [(1, 1, 1, 16)]     0           []                               \n",
      " ayer)                                                                                            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (1, 3)               51          ['stream_3[0][0]']               \n",
      "                                                                                                  \n",
      " tf_op_layer_streaming/stream/s  [(1, 3, 65, 1)]     0           ['stream/ExternalState[0][0]']   \n",
      " trided_slice (TensorFlowOpLaye                                                                   \n",
      " r)                                                                                               \n",
      "                                                                                                  \n",
      " tf_op_layer_streaming/stream_1  [(1, 1, 62, 16)]    0           ['stream_1/ExternalState[0][0]'] \n",
      " /strided_slice (TensorFlowOpLa                                                                   \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " tf_op_layer_streaming/stream_2  [(1, 5, 61, 16)]    0           ['stream_2/ExternalState[0][0]'] \n",
      " /strided_slice (TensorFlowOpLa                                                                   \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " tf_op_layer_streaming/stream_3  [(1, 0, 1, 16)]     0           ['stream_3/ExternalState[0][0]'] \n",
      " /strided_slice (TensorFlowOpLa                                                                   \n",
      " yer)                                                                                             \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (1, 3)               0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " tf_op_layer_streaming/stream/c  [(1, 4, 65, 1)]     0           ['tf_op_layer_streaming/stream/st\n",
      " oncat (TensorFlowOpLayer)                                       rided_slice[0][0]',              \n",
      "                                                                  'my_reshape[0][0]']             \n",
      "                                                                                                  \n",
      " tf_op_layer_streaming/stream_1  [(1, 2, 62, 16)]    0           ['tf_op_layer_streaming/stream_1/\n",
      " /concat (TensorFlowOpLayer)                                     strided_slice[0][0]',            \n",
      "                                                                  'activation[0][0]']             \n",
      "                                                                                                  \n",
      " tf_op_layer_streaming/stream_2  [(1, 6, 61, 16)]    0           ['tf_op_layer_streaming/stream_2/\n",
      " /concat (TensorFlowOpLayer)                                     strided_slice[0][0]',            \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf_op_layer_streaming/stream_3  [(1, 1, 1, 16)]     0           ['tf_op_layer_streaming/stream_3/\n",
      " /concat (TensorFlowOpLayer)                                     strided_slice[0][0]',            \n",
      "                                                                  'stream_2[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 819\n",
      "Trainable params: 723\n",
      "Non-trainable params: 96\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from kws_streaming.layers.modes import Modes\n",
    "\n",
    "model_stream = my_to_streaming_inference(model_non_stream_batch, SMALL_INPUT, Modes.STREAM_EXTERNAL_STATE_INFERENCE)\n",
    "\n",
    "model_stream.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nq201\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\engine\\training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "X_train = np.load('X_train.npy') \n",
    "y_train = np.load('y_train.npy')\n",
    "\n",
    "\n",
    "X_train = np.float32(X_train)\n",
    "X_train = np.float32(X_train)\n",
    "# y_train = np.int32(y_train)\n",
    "# X_train = X_train[0: 10, :]\n",
    "# Parameters\n",
    "segment_length = SMALL_INPUT\n",
    "num_segments = 650 // segment_length\n",
    "\n",
    "# Reshape X_train\n",
    "# Reshape each row of X_train into 25 segments of length 26\n",
    "X_train_reshaped = X_train.reshape(-1, num_segments, segment_length)\n",
    "# Reshape y_train\n",
    "# Replicate each label 50 times\n",
    "y_train_replicated = np.repeat(y_train, num_segments)\n",
    "\n",
    "X_train_reshaped = X_train_reshaped.reshape(-1, segment_length)\n",
    "\n",
    "inputs = []\n",
    "for s in range (len(model_stream.inputs)):\n",
    "  inputs.append(np.zeros(shape=model_stream.inputs[s].shape))\n",
    "\n",
    "save_input_for_later_quantization = []\n",
    "\n",
    "\n",
    "# use model_stream to calculate the output and save it in the input_1, input_2, input_3, input_4, input_5, input_6\n",
    "# the input_1, input_2, input_3, input_4, input_5, input_6 is the ouput of the previous run\n",
    "# the input_1, input_2, input_3, input_4, input_5, input_6 is the input of the next run\n",
    "accuracy = 0\n",
    "for i in range (0, X_train_reshaped.shape[0]):\n",
    "\n",
    "  # reset the input_1, input_2, input_3, input_4, input_5, input_6\n",
    "  if i % num_segments == 0 and i != 0: \n",
    "    for s in range (len(model_stream.inputs)):\n",
    "      inputs[s] = np.zeros(shape=model_stream.inputs[s].shape)\n",
    "  inputs[0] = X_train_reshaped[i, :]\n",
    "  inputs[0] = inputs[0].reshape(1, segment_length)\n",
    "\n",
    "  output = model_stream.predict(inputs)\n",
    "\n",
    "  if (i + 1) % num_segments == 0: \n",
    "\n",
    "    if (np.argmax(output[0]) == y_train[i // num_segments]):\n",
    "      accuracy += 1\n",
    "\n",
    "    save_input_for_later_quantization.append(inputs.copy())\n",
    "\n",
    "  # reset the input_1, input_2, input_3, input_4, input_5, input_6\n",
    "  for s in range(1, len(model_stream.inputs)):\n",
    "    inputs[s] = output[s]\n",
    "\n",
    "\n",
    "# save_input_for_later_quantization = np.array(save_input_for_later_quantization)\n",
    "# def generator():\n",
    "#   for i in range (len(save_input_for_later_quantization)):\n",
    "#     yield save_input_for_later_quantization[i]\n",
    "\n",
    "# ouput_signature = [] \n",
    "# for s in range (len(model_stream.inputs)):\n",
    "#   ouput_signature.append(tf.TensorSpec(shape=model_stream.inputs[s].shape, dtype=tf.float32))\n",
    "input = save_input_for_later_quantization[0]\n",
    "\n",
    "\n",
    "# train_dataset = tf.data.Dataset.from_generator(generator, output_signature=tuple(ouput_signature))\n",
    "def representative_data_gen():\n",
    "  for i in range (len(save_input_for_later_quantization)):\n",
    "\n",
    "    yield save_input_for_later_quantization[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nq201\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\lite\\python\\convert.py:789: UserWarning: Statistics for quantized inputs were expected, but not specified; continuing anyway.\n",
      "  warnings.warn(\"Statistics for quantized inputs were expected, but not \"\n"
     ]
    }
   ],
   "source": [
    "def representative_data_gen():\n",
    "    for input_value in save_input_for_later_quantization:\n",
    "        yield input_value\n",
    "\n",
    "tflite_streaming_model = utils.model_to_tflite(sess, Modes.STREAM_EXTERNAL_STATE_INFERENCE, model_stream=model_stream,\n",
    "                                               optimizations=[tf.lite.Optimize.DEFAULT],supported_ops_override =  [tf.lite.OpsSet.TFLITE_BUILTINS_INT8],\n",
    "                                                  representative_dataset=representative_data_gen)\n",
    "                                        \n",
    "                                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tflite model\n",
    "\n",
    "tflite_streaming_model_path = 'model_stream_external.tflite'\n",
    "\n",
    "with open(tflite_streaming_model_path, 'wb') as f:\n",
    "    f.write(tflite_streaming_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_tflite_quantization(model_path):\n",
    "    # Load the TFLite model\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    # Get details of tensors\n",
    "    tensor_details = interpreter.get_tensor_details()\n",
    "\n",
    "    # Find tensors that are not quantized\n",
    "    non_quantized_tensors = [tensor['name'] for tensor in tensor_details if tensor['dtype'] not in [tf.int8, tf.uint8, tf.int16]]\n",
    "\n",
    "    if non_quantized_tensors:\n",
    "        return \"not quantized\", non_quantized_tensors\n",
    "    else:\n",
    "        return \"quantized\", []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not quantized\n",
      "streaming/stream_3/stream_3/ExternalState\n",
      "streaming/my_reshape/Reshape/shape\n",
      "streaming/stream_2/strided_slice\n",
      "streaming/stream/strided_slice\n",
      "streaming/stream_2/strided_slice1\n",
      "streaming/stream_1/strided_slice\n",
      "streaming/stream_2/strided_slice2\n",
      "streaming/dense/bias\n",
      "streaming/batch_normalization_2/beta\n",
      "streaming/batch_normalization_1/beta\n",
      "streaming/batch_normalization/beta\n"
     ]
    }
   ],
   "source": [
    "status, non_quantized_tensors = check_tflite_quantization(tflite_streaming_model_path)\n",
    "print(status)\n",
    "if non_quantized_tensors:\n",
    "    for tensor in non_quantized_tensors:\n",
    "        print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3686\n",
      "(3686,)\n",
      "0.946825827455236\n"
     ]
    }
   ],
   "source": [
    "# train data accuracy \n",
    "accuracy = 0\n",
    "count = 0\n",
    "for input in save_input_for_later_quantization:\n",
    "    output = model_stream.predict(input)\n",
    "    if np.argmax(output[0]) == y_train[count]:\n",
    "        accuracy += 1\n",
    "    count = count + 1\n",
    "\n",
    "print(len(save_input_for_later_quantization))\n",
    "print(y_train.shape)\n",
    "print(accuracy / len(save_input_for_later_quantization))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy = 0\n",
    "# count = 0\n",
    "# print(X_train.shape)\n",
    "# for test in X_train:\n",
    "#     # print(test.shape)\n",
    "#     test = test.reshape(1, 650)\n",
    "#     output = model_non_stream_batch.predict(test)\n",
    "#     if np.argmax(output[0]) == y_train[count]:\n",
    "#         accuracy += 1\n",
    "#     count = count + 1\n",
    "# print(accuracy / len(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy on test data\n",
      "0.8535791757049892\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import python_speech_features as psf\n",
    "import scipy.signal\n",
    "interpreter = tf.lite.Interpreter(model_path='model_stream_external.tflite')\n",
    "\n",
    "interpreter.allocate_tensors()\n",
    "\n",
    "input_details = interpreter.get_input_details()\n",
    "count = 0\n",
    "accuracy = 0\n",
    "\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "SAMPLE_RATE  = 16000\n",
    "WIN_LEN       =0.02\n",
    "WIN_STEP      =0.02\n",
    "NUM_CEP       =13\n",
    "NUM_FILTERS   =26\n",
    "NUM_FFT       =512\n",
    "LOWFREQ       =0\n",
    "HIGHFRWQ      =SAMPLE_RATE/2\n",
    "PREEMPH       =0.97\n",
    "CEP_LIFTER   = 22\n",
    "APPEND_ENERGY = True\n",
    "\n",
    "\n",
    "temp_inputs = []\n",
    "for s in range (len(input_details)):\n",
    "  temp_inputs.append(np.zeros(shape=input_details[s]['shape'], dtype=np.float32))\n",
    "\n",
    "count = 0\n",
    "accuracy = 0\n",
    "X_test = np.load('X_test.npy')\n",
    "y_test = np.load('y_test.npy')\n",
    "\n",
    "for x in X_test:\n",
    "    for i in range(0, 650, SMALL_INPUT):\n",
    "        temp = x[i:i+SMALL_INPUT]\n",
    "        if input_details[0]['dtype'] == np.int8:\n",
    "            scale, zero_point = input_details[0]['quantization']\n",
    "            temp = np.array((temp / scale) + zero_point, dtype=np.int8)\n",
    "        temp = temp.reshape(1, SMALL_INPUT)\n",
    "        interpreter.set_tensor(input_details[0]['index'], temp)\n",
    "\n",
    "        for i in range(1, len(input_details)):\n",
    "            if input_details[i]['dtype'] == np.int8:\n",
    "                scale, zero_point = input_details[i]['quantization']\n",
    "                temp_inputs[i] = np.array((temp_inputs[i] / scale) + zero_point, dtype=np.int8)\n",
    "            interpreter.set_tensor(input_details[i]['index'], temp_inputs[i])\n",
    "        \n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[0]['index'])\n",
    "        for i in range(1, len(input_details)):\n",
    "            temp_inputs[i] = interpreter.get_tensor(output_details[i]['index'])\n",
    "            temp_inputs[i] = np.array(temp_inputs[i], dtype=np.float32)\n",
    "            scale, zero_point = output_details[i]['quantization']\n",
    "            temp_inputs[i] = (temp_inputs[i] - zero_point) * scale\n",
    "        \n",
    "\n",
    "    if np.argmax(output[0]) == y_test[count]:\n",
    "        accuracy += 1\n",
    "    count = count + 1\n",
    "\n",
    "print(\"accuracy on test data\")\n",
    "print(accuracy / len(X_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
